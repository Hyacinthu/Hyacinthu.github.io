---
title: 李宏毅机器学习笔记-2-关于训练的指南
date: 2022-05-04 14:00:00 +0800
categories: [机器学习入门]
tags: [李宏毅机器学习课程笔记]
pin: false
author: 郑威琦

toc: true
comments: true
math: false
mermaid: true

---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

# 训练指南

## 1、Loss on tranining data is large

&emsp;&emsp;在训练的过程当中，我们会输入training data来训练一开始我们设定的模型，当然，训练的过程本身就是迭代更新参数的过程。那么我们所训练的模型是否能够有很好的预测结果呢？这就涉及到对模型的优化和选择。当然，优化与选择也不是凭空进行的，而是对训练中看到的一些现象做出相应的分析和应对。  

&emsp;&emsp;这里主要就给出李宏毅老师的训练指南，粗浅的给出一些问题的解决方案。如图：

![General Guide](/assets/blog_res/2022-05-04-Wednesday.assets/General%20Guide.png){:hight="50%" width="50%"}

&emsp;&emsp;如果训练的效果不尽如人意，首先要检查在训练集上的误差有多大，如果训练集上的误差都很大，那么说明目前的模型是有问题的，具体问题可以分成两种。第一种是模型的问题，目前基于源模型训练得到的集合中，没有可以使得误差较小的模型，此时就需要更换模型，加深模型的深度，像增加特征、增加神经网络层数以增加深度等等。那么第二种就是Optimizaiton做得不好，没有找到一组参数能够使得误差较小。针对这种问题可以去关注梯度下降算法、是否陷入到了局部最优等。  

&emsp;&emsp;李宏毅老师在讲解这两种问题的时候给出的比喻十分生动也很准确。如果把模型训练比作大海捞针，那么前者是针不在你捞的海，后者则是你怎么捞也捞不到那根存在于海中的针。  

&emsp;&emsp;那么如何区分这两种问题呢？当准备训练模型去解决一个新的问题时候，首先最好使用一些浅层的模型去训练，因为这些模型的Optimization已经做的比较充分。再使用深层的模型训练，若发现深层模型的误差比浅层的还要大，那么就是Optimization的问题。这一问题的解决在接下来的课程中会有讲解。

## 2、Loss on training data is small

## *（1）Loss on testing data is large*

&emsp;&emsp; 当训练集的误差较小，而测试集的误差较大时，相对比较容易解决的问题便是过拟合（overfitting），另外一个则是分布不匹配（mismatch）。

## *①过拟合*

&emsp;&emsp;直接先来一张图，这张图大概展示了overfitting的现象。

![overfitting](/assets/blog_res/2022-05-04-Wednesday.assets/overfitting.png){:hight="50%" width="50%"}

&emsp;&emsp;至于说深度较大、参数较多的模型为什么会产生这样的曲线，会在之后的课程当中从数学的角度去说明。  

&emsp;&emsp;我个人理解过拟合的现象其实就是由于训练集的大小、多样性等与其深度、参数数量、特征维度等不相匹配所造成的，并不是单方向上的训练集少了或者是参数多了。

&emsp;&emsp;那么解决过拟合的最简单的方法就是增加训练资料，使模型被适当的限制住。增加训练资料最简单的就是根据原有的资料制作合乎情理的新资料。比如：

![solution to overfitting](/assets/blog_res/2022-05-04-Wednesday.assets/overfitting.png){:hight="50%" width="50%"}

&emsp;&emsp;像CNN是一个比较有限制的模型，它是根据影像的特性进而限制，而全连接的神经网络其实是比较灵活的。

![solutiong to overfitting 2](/assets/blog_res/2022-05-04-Wednesday.assets/solution%20to%20overfitting%202.png){:hight="50%" width="50%"}

## *②分布不匹配*

&emsp;&emsp;举个最简单的例子，在概率论中我们学过均匀分布和正态分布，本来你基于训练集训练出来的是个正态分布，完了测试集是个均匀分布，那误差不大才怪呢。  

![Mismatch](/assets/blog_res/2022-05-04-Wednesday.assets/Mismatch.png){:hight="50%" width="50%"}

&emsp;&emsp;是不是mismathc往往要看数据的产生方式，以及对问题的理解等等。具体的应对在作业10处会进行讲解。

## *（2）Loss on testing data is small*

&emsp;&emsp;这种训练完成了。

## 3、如何选择/找到一个合适的模型

![loss and model complex](/assets/blog_res/2022-05-04-Wednesday.assets/loss%20and%20model%20complex.png){:hight="50%" width="50%"}

&emsp;&emsp;在这节课程中提到的方式是交叉验证（cross validation），将训练集分为Training Set和Validation Set来进行训练和验证。

&emsp;&emsp;进一步的有N-fold Cross Validation

![N-fold cross validation](/assets/blog_res/2022-05-04-Wednesday.assets/N-fold%20cross%20validation.png){:hight="50%" width="50%"}

# （二）本节课遗留问题

## 1、如何解决Optimization的问题

## 2、在数学上，深度较大、参数较多的模型为什么会产生灵活多变的曲线

## 3、如何判断误差较大是由于分布不匹配（mismatch）产生的，并且如何解决？