---
title: 组会分享（一）
date: 2022-04-27 09:00:00 +0800
categories: [组会]
tags: [组会个人分享]
pin: false
author: 郑威琦

toc: true
comments: true
math: false
mermaid: true

---

## 1 前沿科技视野拓展

[小蛮驴“沦陷”事件](https://www.bilibili.com/video/BV1b3411K7f1?spm_id_from=333.880.my_history.page.click)

[CVPR2022（IEEE国际计算机视觉与模式识别会议）](https://zhuanlan.zhihu.com/p/478648512)

[机器之心](https://www.jiqizhixin.com/articles/2022-04-19-3)

量子位

## 2 个人博客搭建

[1分钟免费博客搭建](https://www.bilibili.com/video/BV14S4y1N7Yr?spm_id_from=333.999.0.0)

## 3 神经网络反向误差传播

### **3.1 神经网络**

&emsp;&emsp;神经网络实质是在生物学基础上（人类神经元）建立起来的数学模型。

![M-P神经元](/assets/blog_res/2022-04-27-Thirsday.assets/M-P神经元.jpg)

&emsp;&emsp;多个神经元同向排列（纵或横）组成一层（layer）。

![神经网络](/assets/blog_res/2022-04-27-Thirsday.assets/神经网络.jpg)

### **3.2 感知机**

&emsp;&emsp;感知机（Perceptron）由两层神经元组成，输入层接收外界输入信号后传递给输出层，输出层为M-P神经元。

![感知机](/assets/blog_res/2022-04-27-Thirsday.assets/Perceptron.jpg)

![感知机计算](/assets/blog_res/2022-04-27-Thirsday.assets/感知机计算0.jpg)

&emsp;&emsp;感知机学习旨在求出将训练数据进行线性划分的分离超平面。  
&emsp;&emsp;感知机的参数更新规则是基于梯度下降的，在这里不多作详述，直接给出西瓜书所给更新规则。

![感知机神经网络更新规则](/assets/blog_res/2022-04-27-Thirsday.assets/感知机神经网络更新规则.jpg)

### **3.3 基于标准梯度下降的误差逆传播算法**

&emsp;&emsp;假设有网络N，其输入层有d个神经元，隐藏层有q个M-P神经元，输出层有l个神经元，且输入层与隐藏层、隐藏层与输出层为全连接。设输入层第i个神经元到隐藏层第h个神经元的权值为ν<sub>ih</sub>，隐藏层第h个神经元的输入为α<sub>h</sub>，阈值为γ<sub>h</sub>，输出为b<sub>h</sub>，隐藏层第h个神经元到输出层第j个神经元的权值为ω<sub>hj</sub>，输出层第j个神经元的输入为β<sub>j</sub>，阈值为θ<sub>j</sub>，输出为y<sub>j</sub>尖。

![net](/assets/blog_res/2022-04-27-Thirsday.assets/net0.jpg)

&emsp;&emsp;并且，令激活函数为Sigmoid函数。

![Sigmoid](/assets/blog_res/2022-04-27-Thirsday.assets/Sigmoid0.jpg)

&emsp;&emsp;由此，根据前向传播规则，我们可计算出这些参数的值：

![cal](/assets/blog_res/2022-04-27-Thirsday.assets/cal%20nums0.jpg)

&emsp;&emsp;然后，由于将网络在(X<sub>k</sub>, Y<sub>k</sub>)上的均方误差视为损失函数，则将损失函数最小化就是我们参数更新的依据，故计算出目标的负梯度方向，并以此对参数进行调整。

&emsp;&emsp;均方误差如下：

![均方误差](/assets/blog_res/2022-04-27-Thirsday.assets/E.jpg)

&emsp;&emsp;根据梯度的数学定义，计算每个参数对应的负梯度。如下：

![前两个参数](/assets/blog_res/2022-04-27-Thirsday.assets/前两个参数0.jpg)

![后两个参数](/assets/blog_res/2022-04-27-Thirsday.assets/后两个参数0.jpg)

&emsp;&emsp;总而言之：

![总之](/assets/blog_res/2022-04-27-Thirsday.assets/总之.jpg)
![g](/assets/blog_res/2022-04-27-Thirsday.assets/g.jpg)
![e](/assets/blog_res/2022-04-27-Thirsday.assets/eh.jpg)

&emsp;&emsp;最后给出算法流程：

![算法流程](/assets/blog_res/2022-04-27-Thirsday.assets/算法流程.jpg)

>
    # 基于梯度下降的权值更新，通过不断地极小化目标函数（欧式距离/均方差）
    def Weight_Update(self, i):
        for j in range(len(self.w)):
            self.w_changes[j] = self.lr * self.y_true[i] * self.x[i][j]
            self.w[j] = self.w[j] + self.w_changes[j]
        self.bias = self.bias + self.y_true[i] * self.lr
>